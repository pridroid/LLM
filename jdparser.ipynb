{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380ed786-30a0-4061-93a6-69fd0e555bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Matching resume with job descriptions...\n",
      "‚û°Ô∏è Checking against JD: dataanalyst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vilas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\Vilas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Checking against JD: softwaretester\n",
      "‚û°Ô∏è Checking against JD: webdeveloper\n",
      "‚úÖ Matching completed. Results saved to C:\\Users\\Vilas\\document scanner\\stage4\\jd_matching_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "\n",
    "# === Configuration ===\n",
    "resume_path = Path(\"resume_folder/resume.pdf\")\n",
    "jd_folder = Path(\"InputJD_Folder\")\n",
    "output_csv = Path(\"jd_matching_results.csv\")\n",
    "\n",
    "# === Load Resume Text ===\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(str(pdf_path))\n",
    "    return \" \".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "\n",
    "# === Chunking ===\n",
    "def chunk_text(text, max_tokens=3000):\n",
    "    sentences = text.split('. ')\n",
    "    chunks, current = [], \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(current) + len(sentence) < max_tokens:\n",
    "            current += sentence + \". \"\n",
    "        else:\n",
    "            chunks.append(current.strip())\n",
    "            current = sentence + \". \"\n",
    "    if current:\n",
    "        chunks.append(current.strip())\n",
    "    return chunks\n",
    "\n",
    "# === Match Resume Against JD ===\n",
    "def match_resume_with_jd(resume_text, jd_text, jd_name):\n",
    "    chunks = chunk_text(resume_text)\n",
    "    summaries = []\n",
    "\n",
    "    # Step 1: Summarize each resume chunk\n",
    "    llm = ChatOpenAI(temperature=0.7, max_tokens=1000, model=\"gpt-3.5-turbo\", openai_api_key=\"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\")\n",
    "\n",
    "    summary_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\", \"jd\"],\n",
    "        template=\"\"\"\n",
    "You are a smart AI assistant helping a student find a job. Summarize how well the resume content below matches the job description.\n",
    "\n",
    "Resume:\n",
    "\\\"\\\"\\\"\n",
    "{text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Job Description:\n",
    "\\\"\\\"\\\"\n",
    "{jd}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "List relevant skills, strengths, and matching points. Keep it brief but meaningful.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt = summary_prompt.format(text=chunk, jd=jd_text)\n",
    "        summary = llm.predict(prompt)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # Step 2: Final match score and comments\n",
    "    merge_prompt = f\"\"\"\n",
    "You're an AI career assistant. Based on the summaries of the student's resume chunks below:\n",
    "\n",
    "{\"\".join(summaries)}\n",
    "\n",
    "And this job description:\n",
    "\n",
    "{jd_text}\n",
    "\n",
    "Evaluate and return a structured JSON with:\n",
    "{{\n",
    "  \"JD Name\": \"{jd_name}\",\n",
    "  \"Match Percentage\": \"<Number between 0-100>\",\n",
    "  \"Key Matching Skills\": [],\n",
    "  \"Resume Fit Summary\": \"<Short summary why this job is a good/bad fit>\"\n",
    "}}\n",
    "Return only valid JSON.\n",
    "\"\"\"\n",
    "\n",
    "    final_response = llm.predict(merge_prompt)\n",
    "    try:\n",
    "        return json.loads(final_response)\n",
    "    except:\n",
    "        return {\n",
    "            \"JD Name\": jd_name,\n",
    "            \"Match Percentage\": 0,\n",
    "            \"Key Matching Skills\": [],\n",
    "            \"Resume Fit Summary\": \"‚ö†Ô∏è Could not parse response properly.\"\n",
    "        }\n",
    "\n",
    "# === Main Execution ===\n",
    "if not resume_path.exists():\n",
    "    print(\"‚ùå Resume not found.\")\n",
    "    exit()\n",
    "\n",
    "resume_text = extract_text_from_pdf(resume_path)\n",
    "jd_files = list(jd_folder.glob(\"*.txt\"))\n",
    "\n",
    "if not jd_files:\n",
    "    print(\"‚ùå No job descriptions found.\")\n",
    "    exit()\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"üîç Matching resume with job descriptions...\")\n",
    "for jd_file in jd_files:\n",
    "    jd_text = jd_file.read_text(encoding=\"utf-8\")\n",
    "    jd_name = jd_file.stem\n",
    "    print(f\"‚û°Ô∏è Checking against JD: {jd_name}\")\n",
    "    match_result = match_resume_with_jd(resume_text, jd_text, jd_name)\n",
    "    results.append(match_result)\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values(by=\"Match Percentage\", ascending=False)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"‚úÖ Matching completed. Results saved to {output_csv.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f20b15-b9a5-4c84-b416-b50b87866fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
